{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444a1f18",
   "metadata": {},
   "source": [
    "## Descripción breve\n",
    "El siguiente código permite comparar rendimiento medio de los modelos utilizados utilizando la muestra en su totalidad.\n",
    "El mismo proporciona el rendiemiento al usar cross varidation con 10 divisiones para cada modelo, proporciona medidas de las curvas de roc y la matriz de confusión de cada modelo sobre una división del 80% de la muestra en entrenamiento y 20% en testeo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0f1b44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score,  mean_squared_error, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "nombres =  [\n",
    "    \"ID\" ,\"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\",\n",
    "    \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\",\n",
    "    \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\",\n",
    "    \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "df = pd.read_csv('wdbc.data', names = nombres)\n",
    "data=df.copy()\n",
    "data.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "data.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "tags= nombres\n",
    "del tags[0]\n",
    "data1=df.copy()\n",
    "data1.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "data1.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "models=[\n",
    "  LogisticRegression(max_iter=1000),DecisionTreeClassifier(),RandomForestClassifier(n_estimators = 200),QuadraticDiscriminantAnalysis(),\n",
    "  LinearDiscriminantAnalysis(), SVC(kernel='linear', C=1.0, probability=True),  SVC(kernel='sigmoid', probability=True ),   SVC(kernel='rbf', probability=True ),  GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=100, random_state=42)\n",
    "  ]\n",
    "\n",
    "\n",
    "\n",
    "model_name=[\n",
    "  'LogisticRegression','DecisionTreeClassifier' ,'RandomForestClassifier','QuadraticDiscriminantAnalysis',\n",
    "  'LinearDiscriminantAnalysis', 'SVC_linear',  'SVC_sigmoid', 'SVC_rbf', ' GradientBoostingClassifier'\n",
    "  ]\n",
    "colors = [\n",
    "    \"#1f77b4\",  # azul\n",
    "    \"#ff7f0e\",  # naranja\n",
    "    \"#2ca02c\",  # verde\n",
    "    \"#d62728\",  # rojo\n",
    "    \"#9467bd\",  # violeta\n",
    "    \"#8c564b\",  # marrón\n",
    "    \"#e377c2\",   # rosado\n",
    "    \"b\"\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "model_trained={}\n",
    "model_score={}\n",
    "for i in range(len(models)):\n",
    "    model=make_pipeline(StandardScaler(),models[i])\n",
    "    score=cross_val_score(model, X_train, y_train, cv=20)\n",
    "    model_score[model_name[i]]=[model,score]\n",
    "    resulting=models[i].fit(X_train_scaled, y_train)\n",
    "    result=resulting.predict(X_test_scaled)\n",
    "    model_trained[model_name[i]]=[result, resulting]\n",
    "    print(f\"{model_name[i]}: {score.mean()}\")\n",
    "plt.figure(figsize=(10,6))\n",
    "scores_list = []\n",
    "for name in model_name:\n",
    "    for fold, score in enumerate(model_score[name][1]):\n",
    "        scores_list.append({\n",
    "            \"Modelo\": name,\n",
    "            \"Fold\": fold + 1,\n",
    "            \"Score\": score\n",
    "        })\n",
    "scores_df = pd.DataFrame(scores_list)\n",
    "\n",
    "# 2. Graficar con stripplot (que incluye jitter automáticamente)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.stripplot(x=\"Modelo\", y=\"Score\", data=scores_df,\n",
    "              jitter=True,  # <--- La magia está aquí\n",
    "              alpha=0.7,    # <--- También puedes añadir alpha\n",
    "              palette=colors) # Usa tu paleta de colores\n",
    "plt.title(\"Comparación del Rendimiento (Strip Plot con Jitter)\")\n",
    "plt.ylabel(\"Accuracy (Rendimiento)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(20,20))\n",
    "for i in range(9):\n",
    "  a1=i//3\n",
    "  a2=i%3\n",
    "  model=model_trained[model_name[i]][1]\n",
    "\n",
    "  Aplicar=model.predict_proba(X_test_scaled)[:,1]\n",
    "  RocCurveDisplay.from_predictions(y_test, Aplicar, ax=ax[a1,a2])\n",
    "  ax[a1,a2].set_title(f\"{model_name[i]}\")\n",
    "plt.savefig(\"RocCurves.png\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(20,20))\n",
    "for i in range(9):\n",
    "  a1=i//3\n",
    "  a2=i%3\n",
    "  model=model_trained[model_name[i]]\n",
    "  cm = confusion_matrix(y_test, model_trained[model_name[i]][0], labels=[1,0])\n",
    "  sns.heatmap(cm, annot=True,ax=ax[a1,a2], fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Maligno\",\"Benigno\"], yticklabels=[\"Maligno\",\"Benigno\"])\n",
    "  ax[a1,a2].set_xlabel(\"Predicho\")\n",
    "  ax[a1,a2].set_ylabel(\"Real\")\n",
    "  ax[a1,a2].set_title(f\"{model_name[i]}\")\n",
    "  print(model_name[i])\n",
    "  print(classification_report(y_test, model_trained[model_name[i]][0]))\n",
    "plt.savefig(\"ConfusionMatrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c5f20",
   "metadata": {},
   "source": [
    "## Descripción del bloque\n",
    "El siguiente bloque de código compara el rendimiento por modelo en cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee04183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score,  mean_squared_error, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def entrenar_crossvalidation(models, model_name, colors, X_train, y_train, ax, namep):\n",
    "  model_score={}\n",
    "  for i in range(len(models)):\n",
    "      model=make_pipeline(StandardScaler(),models[i])\n",
    "      score=cross_val_score(model, X_train, y_train, cv=10)\n",
    "      model_score[model_name[i]]=[model,score]\n",
    "  scores_list = []\n",
    "  for name in model_name:\n",
    "      for fold, score in enumerate(model_score[name][1]):\n",
    "          scores_list.append({\n",
    "              \"Modelo\": name,\n",
    "              \"Fold\": fold + 1,\n",
    "              \"Score\": score\n",
    "          })\n",
    "  scores_df = pd.DataFrame(scores_list)\n",
    "  sns.stripplot(x=\"Modelo\", y=\"Score\", data=scores_df,\n",
    "                jitter=True,\n",
    "                alpha=0.7,\n",
    "                palette=colors, ax=ax)\n",
    "\n",
    "  ax.set_title(namep)\n",
    "  ax.set_ylabel(\"Accuracy por muestra\")\n",
    "  ax.set_xticklabels(model_name, rotation=45, ha=\"right\")\n",
    "  ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "  return model_score\n",
    "nombres =  [\n",
    "    \"ID\" ,\"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\",\n",
    "    \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\",\n",
    "    \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\",\n",
    "    \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "df = pd.read_csv('wdbc.data', names = nombres)\n",
    "df.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "df.drop(columns=[\"ID\"], inplace=True)\n",
    "tags= nombres\n",
    "del tags[0]\n",
    "data={}\n",
    "for j in range(4):\n",
    "  data1=df.copy()\n",
    "  if j==0:\n",
    "      tag= [\"perimeter\",\"area\" ]\n",
    "  elif j==1:\n",
    "      tag = [\"perimeter\",\"area\", \"compactness\", \"concavity\", \"fractal_dimension\"]\n",
    "  elif j==2:\n",
    "      tag = [\"perimeter\",\"area\", \"compactness\", \"concavity\" ,\"fractal_dimension\", \"symmetry\"]\n",
    "  elif j==3:\n",
    "       tag = [\"perimeter\",\"area\", \"compactness\", \"concavity\" ,\"texture\", \"smoothness\",\"fractal_dimension\", \"symmetry\"]\n",
    "  for i in range(3):\n",
    "      tags = [c+str(i+1) for c in tag]\n",
    "      data1.drop(columns=tags, inplace=True)\n",
    "  data1.drop(columns= 'radius3', inplace=True)\n",
    "  X=data1.drop(columns=[\"Diagnosis\"]).to_numpy()\n",
    "  Y=data1[\"Diagnosis\"].to_numpy()\n",
    "  data[j]=[X,Y]\n",
    "models=[\n",
    "  LogisticRegression(max_iter=1000),DecisionTreeClassifier(),RandomForestClassifier(n_estimators = 200),QuadraticDiscriminantAnalysis(),\n",
    "  LinearDiscriminantAnalysis(), SVC(kernel='linear', C=1.0, probability=True),  SVC(kernel='sigmoid', probability=True ),   SVC(kernel='rbf', probability=True ),  GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=100, random_state=42)\n",
    "  ]\n",
    "\n",
    "model_name=[\n",
    "  'LogisticRegression','DecisionTreeClassifier' ,'RandomForestClassifier','QuadraticDiscriminantAnalysis',\n",
    "  'LinearDiscriminantAnalysis', 'SVC_linear',  'SVC_sigmoid', 'SVC_rbf', ' GradientBoostingClassifier'\n",
    "  ]\n",
    "colors = [\n",
    "    \"#1f77b4\",  # azul\n",
    "    \"#ff7f0e\",  # naranja\n",
    "    \"#2ca02c\",  # verde\n",
    "    \"#d62728\",  # rojo\n",
    "    \"#9467bd\",  # violeta\n",
    "    \"#8c564b\",  # marrón\n",
    "    \"#e377c2\",   # rosado\n",
    "    \"b\"\n",
    "]\n",
    "names=[\"data_1\", \"data_2\", \"data_3\", \"data_4\"]\n",
    "fig, ax= plt.subplots(ncols=2, nrows=2, figsize=(20,20))\n",
    "model_score={}\n",
    "for i in range(4):\n",
    "  a1=i//2\n",
    "  a2=i%2\n",
    "  X=data[i][0]\n",
    "  y=data[i][1]\n",
    "  model_score[i]=entrenar_crossvalidation(models=models, model_name=model_name, colors=colors, X_train=X, y_train=y, ax=ax[a1,a2], namep=f\"data{i}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Comparacion.png\")\n",
    "plt.show()\n",
    "vector=[]\n",
    "for i in range(4):\n",
    "  vect=[]\n",
    "  score=model_score[i]\n",
    "  for name in model_name:\n",
    "    vect.append(score[name][1].mean())\n",
    "  vector.append(vect)\n",
    "dataframe=pd.DataFrame(vector, columns=model_name)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831ad88",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "El siguirnte código muestra los histogramas por covariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78577705",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.copy()\n",
    "data.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "\n",
    "dataA=data[data['Diagnosis']==1]\n",
    "dataB=data[data['Diagnosis']==0]\n",
    "\n",
    "dataA=dataA.drop(columns=[\"Diagnosis\"])\n",
    "dataB=dataB.drop(columns=[\"Diagnosis\"])\n",
    "tagsA=dataA.keys()\n",
    "tagsB=dataB.keys()\n",
    "print(len(tagsA))\n",
    "print(len(tagsB))\n",
    "fig, ax = plt.subplots(ncols=5, nrows=6, figsize=(30,30))\n",
    "for i in range(30):\n",
    "  a1=i//5\n",
    "  a2=i%5\n",
    "  ax[a1,a2].set_title(tagsA[i])\n",
    "  ax[a1,a2].hist(dataA[tagsA[i]], color='r', alpha=0.5, bins=30,label=f\"Diagnosis:{1}\")\n",
    "  ax[a1,a2].hist(dataB[tagsB[i]], color='b', alpha=0.5, bins=30, label=f\"Diagnosis:{0}\")\n",
    "  ax[a1,a2].legend()\n",
    "plt.savefig(\"Histogramas.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c07670",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "Códigos que permiten obtener los datos de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score,  mean_squared_error, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "nombres =  [\n",
    "    \"ID\" ,\"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\",\n",
    "    \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\",\n",
    "    \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\",\n",
    "    \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "df = pd.read_csv('wdbc.data', names = nombres)\n",
    "data=df.copy()\n",
    "data.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "data.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "\n",
    "n=30\n",
    "tags= nombres\n",
    "del tags[0]\n",
    "data1=df.copy()\n",
    "data1.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "data1.drop(columns=[\"ID\"], inplace=True)\n",
    "X=data1.drop(columns=[\"Diagnosis\"]).to_numpy()\n",
    "Y=data1[\"Diagnosis\"].to_numpy()\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=n)\n",
    "principalComponents = pca.fit_transform(X_scaled)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component '+str(i) for i in range(1,n+1)])\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"PCA\")\n",
    "plt.xlabel(\"principal component 1\")\n",
    "plt.ylabel(\"principal component 2\")\n",
    "plt.scatter(principalDf[\"principal component 1\"], principalDf[\"principal component 2\"], c=Y, cmap=\"viridis\")\n",
    "plt.show()\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_[:10].sum())\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(20,20))\n",
    "for i in range(3*3):\n",
    "  j=i//3\n",
    "  k=i%3\n",
    "  ax[j,k].scatter(principalDf[\"principal component \"+str(1)], principalDf[\"principal component \"+str(k+j*3+2)], c=Y, cmap=\"viridis\")\n",
    "  ax[j,k].set_xlabel(f\"principal component {1}\")\n",
    "  ax[j,k].set_ylabel(f\"principal component {j*3+k+2}\")\n",
    "  plt.savefig(\"PCA.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "tags=data1.drop(columns=[\"Diagnosis\"]).keys()\n",
    "m=9\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20,20)) # Changed nrows from 3 to 4\n",
    "for j in range(m):\n",
    "  z1=j//3\n",
    "  z2=j%3\n",
    "  ax[z1,z2].set_title(f\"PCA component {j+1}\")\n",
    "  ax[z1,z2].bar(tags,np.abs(pca.components_[j])/np.abs(pca.components_[j]).sum())\n",
    "  ax[z1,z2].set_xticklabels(tags, rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"PCAHistograma.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75283c63",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "El siguiente código genera la matriz de correlación, hay multiples porque en principio consideramos incluir solo secciones dada la enorme cantidad de covariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score,  mean_squared_error\n",
    "nombres =  [\n",
    "    \"ID\" ,\"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\",\n",
    "    \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\",\n",
    "    \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\",\n",
    "    \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "df = pd.read_csv('wdbc.data', names = nombres)\n",
    "data=df.copy()\n",
    "data.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "data.head()\n",
    "data.drop(columns=[\"ID\"], inplace=True)\n",
    "data.head()\n",
    "for i in range(3):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  tags = [\"Diagnosis\",\n",
    "      \"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\",\n",
    "      \"concavity\", \"concave_points\", \"symmetry\", \"fractal_dimension\"]\n",
    "  tags = [c+str(i+1) for c in tags]\n",
    "  tags[0]=\"Diagnosis\"\n",
    "  data1 = data[tags]\n",
    "  Corr_matrix1 =  data1.corr(numeric_only=True)\n",
    "  sns.heatmap(Corr_matrix1, annot=True, cmap='coolwarm')\n",
    "  #  plt.savefig(\"correlation_Matrix\"+str(i+1)+\".png\")\n",
    "  plt.show()\n",
    "for j in range(3):\n",
    "  for i in range(3):\n",
    "      if i<=j:\n",
    "        continue\n",
    "      plt.figure(figsize=(20, 20))\n",
    "      tags = [\"Diagnosis\",\n",
    "          \"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\",\n",
    "          \"concavity\", \"concave_points\", \"symmetry\", \"fractal_dimension\"]\n",
    "      tags = [c+str(i+1) for c in tags]\n",
    "      tags[0]=\"Diagnosis\"\n",
    "      tagsx = [\"Diagnosis\",\n",
    "          \"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\",\n",
    "          \"concavity\", \"concave_points\", \"symmetry\", \"fractal_dimension\"]\n",
    "      tagsx = [c+str(j+1) for c in tagsx]\n",
    "      tagsx[0]=\"Diagnosis\"\n",
    "      tagsy=tags+tagsx\n",
    "      data1 = data[tagsy]\n",
    "      Corr_matrix1 =  data1.corr(numeric_only=True)\n",
    "      sns.heatmap(Corr_matrix1, annot=True, cmap='coolwarm')\n",
    "      # plt.savefig(\"correlation_Matrix\"+str(i+1)+str(j+1)+\".png\")\n",
    "      plt.show()\n",
    "Corr=data.corr(numeric_only=True)\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(Corr, annot=True, cmap='coolwarm')\n",
    "plt.savefig(\"Correlation_Matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e79317",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "Esto no se incluyo en el informe, pero refuerza parte de su análisis y es la relevancia de las covariables en random forest sobre toda la muestra (sin limpiar ningun dato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text\n",
    "from collections import Counter\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score,  mean_squared_error\n",
    "nombres =  [\n",
    "    \"ID\" ,\"Diagnosis\",\n",
    "    \"radius1\", \"texture1\", \"perimeter1\", \"area1\", \"smoothness1\", \"compactness1\",\n",
    "    \"concavity1\", \"concave_points1\", \"symmetry1\", \"fractal_dimension1\",\n",
    "    \"radius2\", \"texture2\", \"perimeter2\", \"area2\", \"smoothness2\", \"compactness2\",\n",
    "    \"concavity2\", \"concave_points2\", \"symmetry2\", \"fractal_dimension2\",\n",
    "    \"radius3\", \"texture3\", \"perimeter3\", \"area3\", \"smoothness3\", \"compactness3\",\n",
    "    \"concavity3\", \"concave_points3\", \"symmetry3\", \"fractal_dimension3\"\n",
    "]\n",
    "data = pd.read_csv('wdbc.data', names = nombres)\n",
    "data.drop(columns=[\"ID\"], inplace=True)\n",
    "data.replace({\"Diagnosis\":{'M': 1, 'B': 0}}, inplace=True)\n",
    "y=data[\"Diagnosis\"].to_numpy()\n",
    "X=data.drop(columns=[\"Diagnosis\"]).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify= y)\n",
    "Tree=RandomForestClassifier(n_estimators=40, oob_score=True, random_state= 42)\n",
    "Tree.fit(X_train, y_train)\n",
    "print(\"Accuracy test:\", Tree.score(X_test, y_test))\n",
    "print(classification_report(y_test, Tree.predict(X_test)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "importances = Tree.feature_importances_\n",
    "\n",
    "feat_names = data.drop(columns=[\"Diagnosis\"]).columns\n",
    "\n",
    "importancia = pd.DataFrame({\n",
    "    \"Feature\": feat_naems,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "print(importancia.head(10))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(importancia[\"Feature\"].head(10), importancia[\"Importance\"].head(10))\n",
    "plt.title(\"Top 10 variables más importantes en Random Forest\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"RandomForestTop.png\")\n",
    "plt.show()\n",
    "RocCurveDisplay.from_predictions(y_test, Tree.predict_proba(X_test)[:,1])\n",
    "plt.title(\"Curva ROC - Random Forest\")\n",
    "plt.savefig(\"RandomForestROC.png\")\n",
    "plt.show()\n",
    "cm = confusion_matrix(y_test, Tree.predict(X_test), labels=[1,0])\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Maligno\",\"Benigno\"], yticklabels=[\"Maligno\",\"Benigno\"])\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de confusión - Random Forest\")\n",
    "plt.savefig(\"RandomForestCM.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
